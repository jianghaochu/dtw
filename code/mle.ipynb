{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) of normal distribution is given by\n",
    "$$\\phi(x) = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{t-\\mu}{\\sigma})^2} dt$$\n",
    "with the Probability Density Function (PDF) being $f(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}$ and the derivative of $\\phi(x)$ is $f(x)$, i.e., $\\phi'(x) = f(x)$.\n",
    "\n",
    "There is no simple formula to evaluate the normal CDF. Instead, there are extensive tables and computational algorithms. One common approach is based on a relationship with the ``error function``. The error function, symbolized by __erf(x)__, is defined by\n",
    "$$\\text{erf}(x) = \\frac{1}{\\sqrt{\\pi}} \\int_{-x}^x \\text{e}^{-t^2}dt$$\n",
    "\n",
    "Thus, the error function can be related to the CDF of normal distribution:\n",
    "$$\\phi(x) =\\frac{1}{2}[1 + \\text{erf}(\\frac{x-\\mu}{\\sqrt{2}\\sigma})]$$\n",
    "\n",
    "The proof is\n",
    "\n",
    "$$\\frac{1}{2}[1 + \\text{erf}(\\frac{x-\\mu}{\\sqrt{2}\\sigma})] = \\int_{-\\infty}^0 \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{t-\\mu}{\\sigma})^2} dt + \\frac{1}{2}\\frac{1}{\\sqrt{\\pi}}\\int_{-\\frac{x-\\mu}{\\sqrt{2}\\sigma}}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt$$\n",
    "\n",
    "The last integral can be simplified by\n",
    "\n",
    "$$\\int_{-\\frac{x-\\mu}{\\sqrt{2}\\sigma}}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt = \\int_{-\\frac{x-\\mu}{\\sqrt{2}\\sigma}}^0 \\text{e}^{-t^2}dt + \\int_{0}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt = 2\\int_{0}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt (\\text{ symmetric w.r.t. t})$$\n",
    "\n",
    "Let $s = \\sqrt{2}\\sigma t + \\mu$, then $0 \\leq s \\leq x$ and $dt = \\frac{1}{\\sqrt{2}\\sigma} ds$,\n",
    "\n",
    "$$\\int_{0}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt = \\frac{1}{\\sqrt{2}\\sigma}\\int_0^x \\text{e}^{-\\frac{1}{2}(\\frac{s-\\mu}{\\sigma})^2}ds$$\n",
    "\n",
    "Therefore,\n",
    "$$\\frac{1}{2}[1 + \\text{erf}(\\frac{x-\\mu}{\\sqrt{2}\\sigma})] = \\int_{-\\infty}^0 \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{s-\\mu}{\\sigma})^2} ds + \\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_0^x \\text{e}^{-\\frac{1}{2}(\\frac{s-\\mu}{\\sigma})^2}ds = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{s-\\mu}{\\sigma})^2} ds$$\n",
    "\n",
    "Specifically, for truncated normal distribution,\n",
    "$$\\int_a^b z \\cdot f(x)dx = 1, \\text{ where } z \\text{ is a scaler and is independent of } x$$\n",
    "\n",
    "So,\n",
    "$$z = \\frac{1}{\\int_a^b f(x)dx} = \\frac{1}{\\phi(b) - \\phi(a)}$$\n",
    "\n",
    "Denote $\\Phi(x)$ as the CDF of ``standard normal distribution``, then \n",
    "$$\\int_a^b f(x)dx = \\int_a^b  \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2} dx = \\int_{\\frac{a-\\mu}{\\sigma}}^{\\frac{b-\\mu}{\\sigma}} \\frac{1}{\\sqrt{2\\pi}}\\text{e}^{-\\frac{1}{2} t^2} dt = \\Phi(\\frac{b-\\mu}{\\sigma})- \\Phi(\\frac{a-\\mu}{\\sigma})$$\n",
    "\n",
    "Then the probability density function (PDF) of truncated normal distribution for $a \\leq x \\leq b$ is \n",
    "$$g(x) = z \\cdot f(x) = \\frac{1}{\\Phi(\\frac{b-\\mu}{\\sigma})- \\Phi(\\frac{a-\\mu}{\\sigma})} \\cdot \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}$$\n",
    "\n",
    "If $a=0$ and $b = +\\infty$, then $\\Phi(\\frac{b-\\mu}{\\sigma}) = 1$ and $\\Phi(\\frac{a-\\mu}{\\sigma}) = \\Phi(-\\frac{\\mu}{\\sigma})$, then the PDF of a normal distribution $N(x \\mid \\mu, \\sigma^2)$ has a $\\mu$ and $\\sigma$-dependent scaling factor, i.e.,\n",
    "\n",
    "$$g(x\\mid \\mu, \\sigma^2) = \\frac{1}{1 - \\Phi(-\\frac{\\mu}{\\sigma})} \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp\\left[{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\\right]$$\n",
    "$$\\Phi(\\omega) = \\frac{1}{2}[1 + \\text{erf}(\\frac{\\omega}{\\sqrt{2}})] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels import api\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>9.461113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>10.052146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.653365</td>\n",
       "      <td>16.571117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.996086</td>\n",
       "      <td>24.532979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.769397</td>\n",
       "      <td>19.908888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.635900</td>\n",
       "      <td>0.360424</td>\n",
       "      <td>12.516907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.032198</td>\n",
       "      <td>0.210653</td>\n",
       "      <td>9.317869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.744781</td>\n",
       "      <td>0.421200</td>\n",
       "      <td>15.450712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.472913</td>\n",
       "      <td>0.218035</td>\n",
       "      <td>11.820892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.121754</td>\n",
       "      <td>0.845753</td>\n",
       "      <td>21.146611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2          y\n",
       "0    0.696469  0.542636   9.461113\n",
       "1    0.286139  0.066774  10.052146\n",
       "2    0.226851  0.653365  16.571117\n",
       "3    0.551315  0.996086  24.532979\n",
       "4    0.719469  0.769397  19.908888\n",
       "..        ...       ...        ...\n",
       "195  0.635900  0.360424  12.516907\n",
       "196  0.032198  0.210653   9.317869\n",
       "197  0.744781  0.421200  15.450712\n",
       "198  0.472913  0.218035  11.820892\n",
       "199  0.121754  0.845753  21.146611\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate an independent variable \n",
    "x = np.random.rand(2, 200)\n",
    "\n",
    "# generate a normally distributed residual\n",
    "e = np.random.normal(10, 5, 200)\n",
    "\n",
    "# generate ground truth\n",
    "y = np.dot(x.T, np.random.uniform(1.0, 15.0, size=2))  + e\n",
    "df = pd.DataFrame(x).T.rename(columns={0: 'x1', 1: 'x2'})\n",
    "df = pd.concat([df, pd.DataFrame(y).rename(columns={0: 'y'})], axis=1)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   48.58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 06 Apr 2023</td> <th>  Prob (F-statistic):</th> <td>7.07e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:41:28</td>     <th>  Log-Likelihood:    </th> <td> -601.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   1208.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   197</td>      <th>  BIC:               </th> <td>   1218.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.0629</td> <td>    0.953</td> <td>    9.507</td> <td> 0.000</td> <td>    7.183</td> <td>   10.943</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    4.3478</td> <td>    1.311</td> <td>    3.316</td> <td> 0.001</td> <td>    1.762</td> <td>    6.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   11.0557</td> <td>    1.182</td> <td>    9.350</td> <td> 0.000</td> <td>    8.724</td> <td>   13.388</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.413</td> <th>  Durbin-Watson:     </th> <td>   1.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.813</td> <th>  Jarque-Bera (JB):  </th> <td>   0.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.069</td> <th>  Prob(JB):          </th> <td>   0.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.781</td> <th>  Cond. No.          </th> <td>    5.56</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.330\n",
       "Model:                            OLS   Adj. R-squared:                  0.324\n",
       "Method:                 Least Squares   F-statistic:                     48.58\n",
       "Date:                Thu, 06 Apr 2023   Prob (F-statistic):           7.07e-18\n",
       "Time:                        22:41:28   Log-Likelihood:                -601.16\n",
       "No. Observations:                 200   AIC:                             1208.\n",
       "Df Residuals:                     197   BIC:                             1218.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.0629      0.953      9.507      0.000       7.183      10.943\n",
       "x1             4.3478      1.311      3.316      0.001       1.762       6.933\n",
       "x2            11.0557      1.182      9.350      0.000       8.724      13.388\n",
       "==============================================================================\n",
       "Omnibus:                        0.413   Durbin-Watson:                   1.936\n",
       "Prob(Omnibus):                  0.813   Jarque-Bera (JB):                0.558\n",
       "Skew:                          -0.069   Prob(JB):                        0.757\n",
       "Kurtosis:                       2.781   Cond. No.                         5.56\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = api.add_constant(df[['x1', 'x2']])\n",
    "model = api.OLS(y, features).fit()\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.888384545924403"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.resid\n",
    "standard_dev = np.std(res)\n",
    "standard_dev"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have $n$ observations and $p$ features (i.e., $p$ coefficients) and denote $X_i = (x_{i1}, \\dots, x_{ip})^T$\n",
    "\n",
    "$$f(y_i|\\beta, \\sigma^2) = N (X_i^T\\beta, \\sigma^2), \\text{ where } \\beta = (\\beta_1, \\dots, \\beta_j, \\dots, \\beta_p)^T$$\n",
    "$$ \\beta_j \\sim N(\\mu_j, \\eta_j^2), \\text{ where } \\mu = (\\mu_1, \\dots, \\mu_p), \\text{ and } \\eta = (\\eta_1, \\dots, \\eta_p)$$\n",
    "\n",
    "Then the joint distribution is \n",
    "$$L(\\beta, \\sigma, \\mu, \\eta) = (\\sqrt{2\\pi}\\sigma)^{-n}\\exp\\{\\frac{\\sum_{i=1}^n(y_i - X_i^T\\beta)^2}{2\\sigma^2}\\} \\times \\prod_{j=1}^p (\\sqrt{2\\pi}\\eta_j)^{-1} \\exp\\{\\frac{(\\beta_j - \\mu_j)^2}{2\\eta_j^2}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLE function\n",
    "def MLE_Norm(parameters):\n",
    "       \n",
    "    beta1, beta2, std_dev = parameters\n",
    "\n",
    "    # predict the output\n",
    "    pred = np.dot(x.T, np.array([beta1, beta2]))\n",
    "    \n",
    "    # Calculate the log-likelihood for normal distribution\n",
    "    LL = np.sum(stats.norm.logpdf(y, pred, std_dev))\n",
    "    \n",
    "    # Calculate the negative log-likelihood\n",
    "    neg_LL = -1*LL\n",
    "    return neg_LL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.66478861, 18.78203099,  7.66490432])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # minimize arguments: function, intial_guess_of_parameters, method\n",
    " mle_model = minimize(MLE_Norm, np.array([2, 2, 2]), method='L-BFGS-B')\n",
    " mle_model.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
