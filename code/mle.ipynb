{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution and Error Function\n",
    "\n",
    "The Cumulative Distribution Function (CDF) of normal distribution is given by\n",
    "$$\\phi(x) = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{t-\\mu}{\\sigma})^2} dt$$\n",
    "with the Probability Density Function (PDF) being $f(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}$ and the derivative of $\\phi(x)$ is $f(x)$, i.e., $\\phi'(x) = f(x)$.\n",
    "\n",
    "There is no simple formula to evaluate the normal CDF. Instead, there are extensive tables and computational algorithms. One common approach is based on a relationship with the ``error function``. The error function, symbolized by __erf(x)__, is defined by\n",
    "$$\\text{erf}(x) = \\frac{1}{\\sqrt{\\pi}} \\int_{-x}^x \\text{e}^{-t^2}dt$$\n",
    "\n",
    "Thus, the error function can be related to the CDF of normal distribution:\n",
    "$$\\phi(x) =\\frac{1}{2}[1 + \\text{erf}(\\frac{x-\\mu}{\\sqrt{2}\\sigma})]$$\n",
    "\n",
    "The proof is\n",
    "\n",
    "$$\\frac{1}{2}[1 + \\text{erf}(\\frac{x-\\mu}{\\sqrt{2}\\sigma})] = \\int_{-\\infty}^0 \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{t-\\mu}{\\sigma})^2} dt + \\frac{1}{2}\\frac{1}{\\sqrt{\\pi}}\\int_{-\\frac{x-\\mu}{\\sqrt{2}\\sigma}}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt$$\n",
    "\n",
    "The last integral can be simplified by\n",
    "\n",
    "$$\\int_{-\\frac{x-\\mu}{\\sqrt{2}\\sigma}}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt = \\int_{-\\frac{x-\\mu}{\\sqrt{2}\\sigma}}^0 \\text{e}^{-t^2}dt + \\int_{0}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt = 2\\int_{0}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt (\\text{ symmetric w.r.t. t})$$\n",
    "\n",
    "Let $s = \\sqrt{2}\\sigma t + \\mu$, then $0 \\leq s \\leq x$ and $dt = \\frac{1}{\\sqrt{2}\\sigma} ds$,\n",
    "\n",
    "$$\\int_{0}^{\\frac{x-\\mu}{\\sqrt{2}\\sigma}} \\text{e}^{-t^2}dt = \\frac{1}{\\sqrt{2}\\sigma}\\int_0^x \\text{e}^{-\\frac{1}{2}(\\frac{s-\\mu}{\\sigma})^2}ds$$\n",
    "\n",
    "Therefore,\n",
    "$$\\frac{1}{2}[1 + \\text{erf}(\\frac{x-\\mu}{\\sqrt{2}\\sigma})] = \\int_{-\\infty}^0 \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{s-\\mu}{\\sigma})^2} ds + \\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_0^x \\text{e}^{-\\frac{1}{2}(\\frac{s-\\mu}{\\sigma})^2}ds = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{s-\\mu}{\\sigma})^2} ds$$\n",
    "\n",
    "Specifically, for truncated normal distribution,\n",
    "$$\\int_a^b z \\cdot f(x)dx = 1, \\text{ where } z \\text{ is a scaler and is independent of } x$$\n",
    "\n",
    "So,\n",
    "$$z = \\frac{1}{\\int_a^b f(x)dx} = \\frac{1}{\\phi(b) - \\phi(a)}$$\n",
    "\n",
    "Denote $\\Phi(x)$ as the CDF of ``standard normal distribution``, then \n",
    "$$\\int_a^b f(x)dx = \\int_a^b  \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2} dx = \\int_{\\frac{a-\\mu}{\\sigma}}^{\\frac{b-\\mu}{\\sigma}} \\frac{1}{\\sqrt{2\\pi}}\\text{e}^{-\\frac{1}{2} t^2} dt = \\Phi(\\frac{b-\\mu}{\\sigma})- \\Phi(\\frac{a-\\mu}{\\sigma})$$\n",
    "\n",
    "Then the probability density function (PDF) of truncated normal distribution for $a \\leq x \\leq b$ is \n",
    "$$g(x) = z \\cdot f(x) = \\frac{1}{\\Phi(\\frac{b-\\mu}{\\sigma})- \\Phi(\\frac{a-\\mu}{\\sigma})} \\cdot \\frac{1}{\\sqrt{2\\pi} \\sigma} \\text{e}^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}$$\n",
    "\n",
    "If $a=0$ and $b = +\\infty$, then $\\Phi(\\frac{b-\\mu}{\\sigma}) = 1$ and $\\Phi(\\frac{a-\\mu}{\\sigma}) = \\Phi(-\\frac{\\mu}{\\sigma})$, then the PDF of a normal distribution $N(x \\mid \\mu, \\sigma^2)$ has a $\\mu$ and $\\sigma$-dependent scaling factor, i.e.,\n",
    "\n",
    "$$g(x\\mid \\mu, \\sigma^2) = \\frac{1}{1 - \\Phi(-\\frac{\\mu}{\\sigma})} \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp\\left[{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\\right]$$\n",
    "$$\\Phi(\\omega) = \\frac{1}{2}[1 + \\text{erf}(\\frac{\\omega}{\\sqrt{2}})] $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels import api\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "n_obs = 5000\n",
    "n_x = 2\n",
    "n_region = 2\n",
    "\n",
    "# define parameters\n",
    "b = np.array([[5,1,2], [10,5,8]])\n",
    "\n",
    "# generate region id\n",
    "id_region = []\n",
    "for i in range(n_region):\n",
    "    id_region += list(np.ones(n_obs, dtype=int)*i)\n",
    "\n",
    "# generate x \n",
    "x = np.ones((n_obs*n_region, n_x+1))\n",
    "x[:, 1:] = np.random.rand(n_obs*n_region, n_x) *10\n",
    "\n",
    "# generate a normally distributed residual\n",
    "e = np.random.normal(0, 1, n_obs*n_region)\n",
    "\n",
    "# generate y\n",
    "y = np.sum(x * b[id_region], axis=1)+e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "      <th>e</th>\n",
       "      <th>id_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.964692</td>\n",
       "      <td>2.861393</td>\n",
       "      <td>17.851749</td>\n",
       "      <td>0.164271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.268515</td>\n",
       "      <td>5.513148</td>\n",
       "      <td>17.487703</td>\n",
       "      <td>-0.807107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.194690</td>\n",
       "      <td>4.231065</td>\n",
       "      <td>22.531296</td>\n",
       "      <td>1.874477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.807642</td>\n",
       "      <td>6.848297</td>\n",
       "      <td>28.252163</td>\n",
       "      <td>-0.252074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.809319</td>\n",
       "      <td>3.921175</td>\n",
       "      <td>18.523444</td>\n",
       "      <td>0.871775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.571459</td>\n",
       "      <td>1.589260</td>\n",
       "      <td>49.145193</td>\n",
       "      <td>-1.426185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.235259</td>\n",
       "      <td>7.247336</td>\n",
       "      <td>93.429420</td>\n",
       "      <td>-0.725566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.652763</td>\n",
       "      <td>7.978197</td>\n",
       "      <td>118.514427</td>\n",
       "      <td>1.425032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.271152</td>\n",
       "      <td>4.450733</td>\n",
       "      <td>52.188191</td>\n",
       "      <td>0.226565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.770733</td>\n",
       "      <td>2.799370</td>\n",
       "      <td>46.949035</td>\n",
       "      <td>0.700409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      const        x1        x2           y         e  id_region\n",
       "0       1.0  6.964692  2.861393   17.851749  0.164271          0\n",
       "1       1.0  2.268515  5.513148   17.487703 -0.807107          0\n",
       "2       1.0  7.194690  4.231065   22.531296  1.874477          0\n",
       "3       1.0  9.807642  6.848297   28.252163 -0.252074          0\n",
       "4       1.0  4.809319  3.921175   18.523444  0.871775          0\n",
       "9995    1.0  5.571459  1.589260   49.145193 -1.426185          1\n",
       "9996    1.0  5.235259  7.247336   93.429420 -0.725566          1\n",
       "9997    1.0  8.652763  7.978197  118.514427  1.425032          1\n",
       "9998    1.0  1.271152  4.450733   52.188191  0.226565          1\n",
       "9999    1.0  2.770733  2.799370   46.949035  0.700409          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a dataframe\n",
    "df = pd.DataFrame(x, columns=['const', 'x1', 'x2'])\n",
    "df['y'], df['e'], df['id_region'] = y, e, id_region\n",
    "df.iloc[np.append(np.arange(0, 5), np.arange(-5, 0)),:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    6.736266\n",
      "x1       3.045522\n",
      "x2       5.123648\n",
      "dtype: float64\n",
      "srqt(SSR/n_obs) = 29.407784795621332\n"
     ]
    }
   ],
   "source": [
    "# Pool OLS\n",
    "ols_pool = api.OLS(df.y, df[['const', 'x1', 'x2']]).fit()\n",
    "print(ols_pool.params)\n",
    "print(f'srqt(SSR/n_obs) = {np.sqrt(ols_pool.ssr/len(df))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ---- Region 0: OLS parameters ----\n",
      "const    4.994363\n",
      "x1       1.000662\n",
      "x2       1.999587\n",
      "dtype: float64\n",
      "srqt(SSR/n_obs) = 1.0005487534245767\n",
      "# ---- Region 1: OLS parameters ----\n",
      "const    9.969552\n",
      "x1       5.004759\n",
      "x2       7.998240\n",
      "dtype: float64\n",
      "srqt(SSR/n_obs) = 0.9845582537636997\n"
     ]
    }
   ],
   "source": [
    "# OLS by regions\n",
    "for i in range(n_region):\n",
    "    print(f'# ---- Region {i}: OLS parameters ----')\n",
    "    features = df.loc[df.id_region==i, ['const', 'x1', 'x2']]\n",
    "    ols_region = api.OLS(df.loc[df.id_region==i].y, features).fit()\n",
    "    print(ols_region.params)\n",
    "    print(f'srqt(SSR/n_obs) = {np.sqrt(ols_region.ssr/n_obs)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE\n",
    "\n",
    "Suppose we have $n$ observations and $p$ features (i.e., $p$ coefficients) and denote $X_i = (x_{i1}, \\dots, x_{ip})^T$\n",
    "\n",
    "$$f(y_i|\\beta, \\sigma^2) = N (X_i^T\\beta, \\sigma^2), \\text{ where } \\beta = (\\beta_1, \\dots, \\beta_j, \\dots, \\beta_p)^T$$\n",
    "$$ \\beta_j \\sim N(\\mu_j, \\eta_j^2), \\text{ where } \\mu = (\\mu_1, \\dots, \\mu_p), \\text{ and } \\eta = (\\eta_1, \\dots, \\eta_p)$$\n",
    "\n",
    "Then the joint distribution is \n",
    "$$L(\\beta, \\sigma, \\mu, \\eta) = (\\sqrt{2\\pi}\\sigma)^{-n}\\exp\\{\\frac{\\sum_{i=1}^n(y_i - X_i^T\\beta)^2}{2\\sigma^2}\\} \\times \\prod_{j=1}^p (\\sqrt{2\\pi}\\eta_j)^{-1} \\exp\\{\\frac{(\\beta_j - \\mu_j)^2}{2\\eta_j^2}\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood function for pool OLS\n",
    "def ll_pool(par_init, X=df[['const', 'x1', 'x2']], y=df['y']):\n",
    "    # data\n",
    "    dt_x = X.copy()\n",
    "    dt_y = y.copy()\n",
    "\n",
    "    # par\n",
    "    b0, b1, b2, sig = par_init\n",
    "\n",
    "    # predict the output\n",
    "    y_hat = dt_x @ np.array([b0, b1, b2])\n",
    "    \n",
    "    # Calculate the log-likelihood for normal distribution\n",
    "    LL = stats.norm.logpdf(dt_y, y_hat, sig)\n",
    "    \n",
    "    # Calculate the negative log-likelihood\n",
    "    neg_LL = -1*np.sum(LL)\n",
    "    return neg_LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary MLE results\n",
    "def mle_summary(mle_obj):\n",
    "    print('MLE success: {0}\\nMLE Obj func value: {1:.2f}\\nMLE pars: {2}'.\\\n",
    "          format(mle_obj.success, mle_obj.fun, [round(x,2) for x in mle_obj.x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE success: True\n",
      "MLE Obj func value: 48001.98\n",
      "MLE pars: [6.74, 3.05, 5.12, 29.41]\n"
     ]
    }
   ],
   "source": [
    "# minimize arguments: function, intial_guess_of_parameters, method\n",
    "mle_pool = minimize(ll_pool, x0=np.array([1, 2, 2, 2]), method='L-BFGS-B')\n",
    "mle_summary(mle_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE success: True\n",
      "MLE Obj func value: 48001.98\n",
      "MLE pars: [6.74, 3.05, 5.12, 29.41]\n"
     ]
    }
   ],
   "source": [
    "# Add opt boundaries for x0\n",
    "mle_pool = minimize(ll_pool, x0=np.array([1, 2, 2, 2]), method='L-BFGS-B', \n",
    "                    bounds=[(0,9), (0,9), (0,9), (1, 99)])\n",
    "mle_summary(mle_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood function for OLS by regions\n",
    "def ll_region(par_init, X=df[['const', 'x1', 'x2']], y=df['y']):\n",
    "    # data\n",
    "    dt_x = X.copy()\n",
    "    dt_y = y.copy()\n",
    "\n",
    "    # par\n",
    "    b0_0, b1_0, b2_0, sig_0, b0_1, b1_1, b2_1, sig_1 = par_init\n",
    "    beta0 = np.array([b0_0, b1_0, b2_0])\n",
    "    beta1 = np.array([b0_1, b1_1, b2_1])\n",
    "\n",
    "    # predict the output\n",
    "    y_hat_0 = dt_x[df.id_region==0] @ beta0\n",
    "    y_hat_1 = dt_x[df.id_region==1] @ beta1\n",
    "\n",
    "    # Calculate the log-likelihood for normal distribution\n",
    "    LL_0 = stats.norm.logpdf(dt_y[df.id_region==0], y_hat_0, sig_0)\n",
    "    LL_1 = stats.norm.logpdf(dt_y[df.id_region==1], y_hat_1, sig_1)\n",
    "    \n",
    "    # Calculate the negative log-likelihood\n",
    "    neg_LL = -1*np.sum(np.append(LL_0, LL_1))\n",
    "    return neg_LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE success: True\n",
      "MLE Obj func value: 14114.32\n",
      "MLE pars: [4.99, 1.0, 2.0, 1.0, 9.97, 5.0, 8.0, 0.98]\n"
     ]
    }
   ],
   "source": [
    "mle_region = minimize(ll_region, x0=np.array([1, 2, 3, 5, 1, 2, 3, 5]), method='L-BFGS-B')\n",
    "mle_summary(mle_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood function for hierarchical OLS\n",
    "def ll_hier(par_init, X=df[['const', 'x1', 'x2']], y=df['y']):\n",
    "    # data\n",
    "    dt_x = X.copy()\n",
    "    dt_y = y.copy()\n",
    "\n",
    "    # par\n",
    "    dev0_0, dev1_0, dev2_0, sig_0, dev0_1, dev1_1, dev2_1, sig_1, \\\n",
    "    b0, sig_b0, b1, sig_b1, b2, sig_b2= par_init\n",
    "    beta0 = np.array([b0+dev0_0*sig_b0, b1+dev1_0*sig_b1, b2+dev2_0*sig_b2])\n",
    "    beta1 = np.array([b0+dev0_1*sig_b0, b1+dev1_1*sig_b1, b2+dev2_1*sig_b2])\n",
    "\n",
    "    # predict the output\n",
    "    y_hat_0 = dt_x[df.id_region==0] @ beta0\n",
    "    y_hat_1 = dt_x[df.id_region==1] @ beta1\n",
    "\n",
    "    # Calculate the log-likelihood for normal distribution\n",
    "    LL_0 = stats.norm.logpdf(dt_y[df.id_region==0], y_hat_0, sig_0) + \\\n",
    "    stats.norm.logpdf(beta0[0], b0, sig_b0) + \\\n",
    "    stats.norm.logpdf(beta0[1], b1, sig_b1) + \\\n",
    "    stats.norm.logpdf(beta0[2], b2, sig_b2)\n",
    "    LL_1 = stats.norm.logpdf(dt_y[df.id_region==1], y_hat_1, sig_1) + \\\n",
    "    stats.norm.logpdf(beta1[0], b0, sig_b0) + \\\n",
    "    stats.norm.logpdf(beta1[1], b1, sig_b1) + \\\n",
    "    stats.norm.logpdf(beta1[2], b2, sig_b2)\n",
    "    \n",
    "    # Calculate the negative log-likelihood\n",
    "    neg_LL = -1*np.sum(np.append(LL_0, LL_1))\n",
    "    return neg_LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE success: True\n",
      "MLE Obj func value: 6490.96\n",
      "MLE pars: [-0.0, -0.02, -0.02, 29.0, 0.0, 0.02, 0.02, 29.0, 6.74, 0.1, 3.05, 0.1, 5.12, 0.1]\n"
     ]
    }
   ],
   "source": [
    "mle_hier = minimize(ll_hier, x0=np.array([.1,.2,.3,5,.1,.2,.3,5,1,1,2,1,3,1]), \n",
    "                    method='L-BFGS-B', \n",
    "                    bounds=[(-1,1), (-1,1), (-1,1), (0, 29), \n",
    "                            (-1,1), (-1,1), (-1,1), (0, 29),\n",
    "                            (0,9), (.1,9), (0,9), (.1, 9), (0,9), (.1, 9)])\n",
    "mle_summary(mle_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE success: True\n",
      "MLE Obj func value: 33414.24\n",
      "MLE pars: [-0.01, -0.09, -1.0, 1.02, 0.01, 0.09, 1.0, 9.0, 5.06, 0.1, 1.06, 0.1, 6.56, 4.6]\n"
     ]
    }
   ],
   "source": [
    "mle_hier = minimize(ll_hier, x0=np.array([.1,.2,.3,5,.1,.2,.3,5,1,1,2,1,3,1]), \n",
    "                    method='L-BFGS-B', \n",
    "                    bounds=[(-9,9), (-9,9), (-9,9), (.1, 9), \n",
    "                            (-9,9), (-9,9), (-9,9), (.1, 9),\n",
    "                            (0,9), (.1,9), (0,9), (.1, 9), (0,9), (.1, 9)])\n",
    "mle_summary(mle_hier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
